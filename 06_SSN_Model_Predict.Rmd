---
title: "James SSN Predictions"
author: "Michael McManus, Travis Linscome-Hatfield"
date: "04/03/2025"
output:
  html_document:
    fig_caption: yes
    number_sections: false
    toc: yes
    toc_float:  yes
    code_folding: hide
    self_contained: yes
    theme: lumen
editor_options: 
  chunk_output_type: console
---


# Outline
Start with a clean environment. This script like all the scripts runs as a stand-alone so that means there is some redundancy in having to modify and transform covariates.

The purpose of this script is to make sure both obs and preds have the same covariates. This is required so that the SSN model built from the obs can then applied to make predictions at the preds. The 48 preds were withheld from from the SSN model building to provide an independent data set for measuring the predictive performance of the SSN model. The 48 preds were collected from spatially balanced probabilistic surveys done from 2019-2022.

Three modifications were made to the SSN WS-WQ model, ssn_wswq_reml1, from script 05 in attempts to get a better predictive model. Those modifications included:
1) Added a partition factor statement to the model based on parallel coordinate plot in script 05 and a boxplot of elevation made in this script (see NMC Elevation Boxplots by Subbasins under the Figures for Presentations section)
2) Based on the literature, tested 3 additional covariates to try and get a better fitting and predictive model,
3) Tested the hypothesis that monitoring sites having upstream waterbodies furthest away would have higher VSCI.

With those modification evaluated, then the final model, which included the partition factor and the nearest distance to upstream waterbody covariate, was evaluated by comparing observed vsci to predicted vsci, first, for the 199 observations from 2001-2018 using leave-one-out-cross-validation (loocv). The second evaluation used the 48 predictions sites from 2019-2022 with their observed vsci compared to the predicted vsci from the SSN model. Both of those evaluations were done with graphs of the observed values on the y-axis and predicted values on the x-axis.

Log Keeping log below for now when reach final version will delete.

01/24/2025 coded for status and trend station types so to evaluate ST_rand model

12/23/2024 Travis walked me through merging his interval_pred_upd branch with main repository on GitHub. Once that was done I pulled that from main repository to my local repository.


12/16/2024 trying to run distance hypothesis using binomial, numerically coded waterbody upstream, 0 is absent and 1 is present, and distance upstream to nearest waterbody as continuous covariate. 

11/25/2024 using James_071024_pluspreds as ssn object as has all 48 prediction points in one shapefile. And bringing additional covariates. Needing to assign 0's to preds_2019_2022 that initially had dist_nearest_up_wb_km set to NA for 31 of 48 prediction points.

11/19/2024 trying to run TLH code chunk for prediction interval graph

On 10/24/2024, went through the code with Travis and now runs without errors all chunks above Status vs Trend Predictions chunk. Pushed to repository.

Trying again on 08/14/2024 to push this code up to github repository.
On 08/13/2024, pushed to github. Trying push again as I don't see this code
on github. 

On 07/12/2024 need to make sure that james_071024.ssn, with PRISM data, gives same prediction output as previous ssn object. It does.

On 07/02/2024 R version 4.4.1 was installed.
On 07/01/2024 added code to include partition factor assignment to preds.

On 06/28/2024 added code to run a parition factor model.

On 06/17/2024 running code to get predictions for 2019-2020 that I put into a geopackage so I map and plot se vs prediction in QGIS.

On 05/14/2024 running code as updated R, RTools, and RStudio on 05/08/2024.

On 04/19/2024 also specify spatial autocovariance of tail down exponential and Euclidean exponential. Also, run MLR of mixed geography using impervious cover of all 4 geographies (to identify high collinearity), elevation at watershed, DO, tothab, and l_tn, and Lower James subbasin. Does that combination of variables better fit and outperform watershed-only model?

On 04/18/2024 now using vsci as response variable not y2.

On 04/17/2024 now using James041724.ssn as it has climate PRISM data out of StreamCat of precip_mm, Tmean, and Tmax.

On 04/09/2024 Mike Dumelle recommended:  1) use untransformed vsci, 2) include absence/presence binary land cover with percent land cover, and 3) include year.

On 04/04/2024 now using James040424.ssn as Ellen D'Amico from Pegasus updated Preds_2021_2022 points.

On 03/27/2024, Using code from step1_james_eda_v1.Rmd, but now specifying preds1 to bring in 22 points from 2019-2020 VDEQ monitoring and preds2 to bring in 26 points from 2021-2022 VDEQ monitoring using current SSN from James.ssn_032224.zip.
# Libraries
```{r setup,message=FALSE, warning=FALSE, collapse=TRUE}

library(SSN2)
library(tidyverse)
library(janitor)
library(readxl)
library(sf)
library(dummy)
library(mapview)
library(leafpop) # for popups in mapview
library(leafsync) # sync mapview maps
library(webshot2) # png of mapview maps
library(GGally)  # parallel coordinate plot
library(performance) # mlr diagnostics
library(car) # added variable plots visualize slopes
library(plotly)
library(corrr) # tidyverse correlation package
library(tmap) # for publication quality maps note this is version tmap_3.3-4 and version 4 is now out
library(tmaptools)
library(shiny)
library(shinyjs) # for tmap color palette

sessionInfo()

# attached base packages:
# [1] stats     graphics  grDevices utils     datasets  methods   base     
# 
# other attached packages:
#  [1] corrr_0.4.4        plotly_4.10.4      performance_0.12.2
#  [4] GGally_2.2.1       leafpop_0.1.0      mapview_2.11.2    
#  [7] dummy_0.1.3        sf_1.0-16          readxl_1.4.3      
# [10] janitor_2.2.0      lubridate_1.9.3    forcats_1.0.0     
# [13] stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2       
# [16] readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      
# [19] ggplot2_3.5.1      tidyverse_2.0.0    SSN2_0.2.1 


knitr::opts_chunk$set(message=FALSE, warning=FALSE,collapse = T)
```

# 1.0 Load SSN Observations and Preds
Notice this import explicitly brings in the prediction points. The SSN object always contained obs and preds, but until now we never called out the preds. Both the obs and preds need to have the same covariates.
```{r ssn_obs_preds}
# now bringing predpts 2019-2022 combined
# current ssn
j_ssn1a <- SSN2::ssn_import("ssn_object/James_071024_pluspreds.ssn", predpts = c("Preds_2019_2022"),
overwrite = FALSE)

names(j_ssn1a)
summary(j_ssn1a)

DFobs <- SSN2::ssn_get_data(j_ssn1a) %>% clean_names(.)

preds1 <- SSN2::ssn_get_data(j_ssn1a, name = "Preds_2019_2022") %>% clean_names(.)


```


# 2.0 Steps for working with preds based on obs

Note that both obs and preds need to be in the SSN object that is modeled. This results in the SSN model object having all the variables needed for the SSN predict function.
	1. Make factors of vahusb and year.
	2. Log total nitrogen. 
	3. Include additional covariates of wastewater treatment plant, depth to bedrock, upstream waterbody as categorical absent or present, and continuous covariate of distance to nearest upstream waterbody.
	4. Empirical logit transformations for impervious and forest
	5. Dummy code transformation of factors for vahusb.

# 2.1 Total Habitat (RBP) score
Bring Total Habitat Score (TotHab) in from Wadeable_ProbMon_2001-2018_Final_Final.xslx spreadsheet so it can be joined to DFobs and then j_ssn1a. These 2 stations:  2-JKS070.97 and 2-DDY000.75_2017 do not have tothab as Emma confirmed in her 11/24/2023 email. Both sites are in Central Appalachian Ridges and Valleys. Both have high VSCI scores of 73.8 and 84.5 (the latter is max VSCI), respectively. I will impute their tothab scores. For trend station 2-DDY000.75_2017, I will average the scores of 172.5, 173.5, and 178 from 2011, 2013, and 2015, respectively. For  2-JKS070.97 on 3rd order, I averaged nearby sites 2-JKS076.16, has tothab of 162.0 on 3rd order, is upstream of 2-JKS070.97, about 16 km apart. Also used Back Creek site, 2-BCC001.90 (has tothab of 189.0 on 2nd order),  that flows parallel to Jackson River, where the 2 sites are, and Back Creek site is near confluence to Jackson River.  2-BCC001.90 is about 9 stream km from 2-JKS070.97. Added new variable tothab.

```{r tothab}

tothab_ds1 <- read_xlsx("data/Wadeable_ProbMon_2001-2018_Final_Final.xlsx", range = "Wadeable_ProbMon_2001-2018!D1:BK814")
                        
tothab_ds2 <- tothab_ds1 |>
  filter(SubBasin == "James") |>
  dplyr::select(StationID_Trend, TotHab) |>
  mutate_at(c('TotHab'), as.numeric)

summary(tothab_ds2$TotHab)

# 2-DDY000.75_2017 is on Daddy Run headwater of Calfpasture River
# https://stackoverflow.com/questions/32829358/dplyr-filter-with-sql-like-wildcard
dr_na <- filter(tothab_ds2, grepl("2-DDY000.75", StationID_Trend, fixed = TRUE))
summary(dr_na$TotHab)

tothab_ds3 <- tothab_ds2|>
  mutate(
    TotHab = case_when(StationID_Trend == "2-DDY000.75_2017" ~ 176.4,
       TRUE ~ TotHab))


# 2-JKS070.97 is on Jackson River
jr_na <- filter(tothab_ds3, StationID_Trend == "2-JKS076.16"| StationID_Trend == "2-BCC001.90")

summary(jr_na$TotHab)

tothab_ds4 <- tothab_ds3|>
  mutate(
    TotHab = case_when(StationID_Trend == "2-JKS070.97" ~ 175.5,
       TRUE ~ TotHab))
# no longer any NAs
summary(tothab_ds4$TotHab)

tothab_ds4 <- rename(tothab_ds4,c(tothab = TotHab, st_id_tren = StationID_Trend ))
head(tothab_ds4)

# add tothab as new variable
DFobs <- full_join(DFobs, tothab_ds4, by = join_by(station_id_2==st_id_tren))

names(DFobs)

# remove datasets not needed downstream
rm(tothab_ds1, tothab_ds2, dr_na, tothab_ds3, jr_na, tothab_ds4)
```

# 2.2 Transform Obs Covariates

```{r transform_obs}
# use code to evaluate vsci by year for trend sites if a random effect for trend stations is needed
DFobs <- DFobs %>%
  mutate(
    st_type = case_when(
      station_id_2 == "2-JKS028.69_2004" ~ "status",
      station_id_2 != "2-JKS028.69_2004" & station_id_2 != station_id ~ "trend",
      station_id_2 != "2-JKS028.69_2004" & station_id_2 == station_id ~ "status",
    )
  )
summary(as.factor(DFobs$st_type))

ggplot(DFobs, aes(x = st_type, y = vscivcpmi)) + geom_boxplot() + labs(title = "Obs from 2001-2018 (n=199)")

select(DFobs, station_id_2, st_type, vscivcpmi) %>% arrange(st_type, vscivcpmi, station_id_2) %>% print(n =Inf)

DFobs$year_f <- as.factor(DFobs$year)
DFobs$vahusb <- factor(DFobs$vahusb, levels = c("JU", "JM", "JR", "JA", "JL"))
summary(DFobs$vahusb)

DFobs <- DFobs %>%
  mutate(
    jl = case_when(
    vahusb != "JL" ~ 0,
    vahusb == "JL" ~1
  )
)

DFobs <- DFobs %>% 
  mutate(
    ju = case_when(
      vahusb == "JU" ~ "yes",
      .default = "no"
    )
  )
DFobs$ju <- factor(DFobs$ju, levels = c("yes","no"))
summary(DFobs$ju)

glimpse(DFobs)
# In ArcGIS these 2 fields are not numeric so have to mutate
DFobs2 <- DFobs %>% mutate_at(c('pct_for_c', 'pct_for_w'), as.numeric)

DFobs2$l_tn <- log(DFobs2$tn)

DFobs2$vsci <- round(DFobs2$vscivcpmi,1)

# WWTP data
wwtp_ds1 <- read.csv("data/WWTP_VA.csv") %>% clean_names(.)

DFobs2 <- left_join(DFobs2, wwtp_ds1, by = join_by(feature_id == comid))

DFobs2 <- DFobs2 %>% 
  mutate(
    wwtp = case_when(
      wwtp_all_dens_ws > 0 ~ "yes",
      wwtp_all_dens_ws == 0 ~ "no"
    )
  )

DFobs2$wwtp <- factor(DFobs2$wwtp, levels = c("yes","no"))
summary(DFobs2$wwtp)

# Statgo2 Set 2 variables, use RckDepWs
statsgo_set2 <- read.csv("data/STATSGO_Set2_VA.csv") %>% clean_names(.)

names(statsgo_set2)

DFobs2 <- left_join(DFobs2, statsgo_set2, by = join_by(feature_id == comid))

# Waterbody data
wb_ds1 <- read.csv("data/ObservationPoints_DistancesUpstream_100424.csv") %>% clean_names(.)
class(wb_ds1)
names(wb_ds1)
head(wb_ds1)
str(wb_ds1)
summary(wb_ds1$num_waterbody_up, na.rm = TRUE)
summary(wb_ds1$dist_nearest_up_wb_km, na.rm = TRUE)
wb_ds1$dist_nearest_up_wb_km <- round(wb_ds1$dist_nearest_up_wb_km, 1)

summary(wb_ds1$dist_nearest_up_wb_km, na.rm = TRUE)
# file below provides a link to waterbody, and subsequently to DFobs data.
StationIDs_UniqLocIDs <- read.csv("data/StationIDs_UniqLocIDs.csv") %>% clean_names(.)

names(StationIDs_UniqLocIDs)

wb_ds2 <- left_join(StationIDs_UniqLocIDs, wb_ds1, by=join_by(uniq_loc_id))
names(wb_ds2)

# from help by = join_by(name == artist)
# station_id_2 and station_id are both long station trend names
DFobs2 <- left_join(DFobs2, wb_ds2, by = join_by(station_id_2==station_id))
names(DFobs2)
DFobs2 <- DFobs2 %>% 
  mutate(
    wbc = case_when(
      incl_nhdwb == "yes" ~ "present",
      incl_nhdwb != "yes" ~ "absent"
    )
  )

class(DFobs2$wbc)

DFobs2$wbc <- factor(DFobs2$wbc, levels = c("present", "absent"))
summary(DFobs2$wbc)

# adding binomial wbc, wbc_bin, coded as numeric 0 or 1 similar to Dumelle et al. 2023 coding in National Lake assessment conductivity paper.

DFobs2 <- DFobs2 %>% 
  mutate(
    wbc_bin = case_when(
      incl_nhdwb == "yes" ~ 1,
      incl_nhdwb != "yes" ~ 0
    )
  )

class(DFobs2$wbc_bin)
DFbos2 <- as.numeric(DFobs2$wbc_bin)
class(DFobs2$bin_wbc)

summary(DFobs2$dist_nearest_up_wb_km)

DFobs2$dist_nearest_up_wb_km[is.na(DFobs2$dist_nearest_up_wb_km)] <- 0

summary(DFobs2$dist_nearest_up_wb_km)

names(DFobs2)

class(DFobs2)
# note ssn_put_data requires sf object and SSN2 object
j_ssn2 <-  SSN2::ssn_put_data(DFobs2,j_ssn1a)
# just doing this assignment so not have to rename objects
j_ssn3 <- j_ssn2

# VARIABLE ADJUSTMENT ZONE 4
### Variables to apply empirical logit transformation
emplog_vars <- c("pct_for_w","pct_imp_w","pct_crop_w","pct_hay_w","pct_grs_w","pct_shrb_w","pct_for_wr","pct_imp_rp_w","pct_crop_wr","pct_hay_wr","pct_grs_wr","pct_shrb_wr","pct_for_c","pct_imp_c","pct_crop_c","pct_hay_c","pct_grs_c", "pct_shrb_c", "pct_for_cr","pct_imp_rp_c","pct_crop_cr","pct_hay_cr","pct_grs_cr","pct_shrb_cr")

# remove geometry so empirical logit can be applied
DFobsz <- st_set_geometry(DFobs2, NULL)
################################################################
################################################################


## transform these variables and put the new values into new columns in DFobs
for(var in emplog_vars){
  ### create new tranformed data column to preserve the original
  new_nm <- paste0(var,"_emplog")
  dat_vec_obs <- DFobsz[,var]
  # dat_vec_preds <- DFpreds[,var]
  
  #converting to 0-1 range
  dat_vec_obs <- dat_vec_obs/100
  # dat_vec_preds <- dat_vec_preds/100
  
  # dat_vec[dat_vec == 1] <- .9999
  # dat_vec[dat_vec == 0] <- .0001
  
  if(any(dat_vec_obs > 1 | dat_vec_obs < 0)){
    cat("ERROR: percentage variables outside logical bounds")
  }
  
  small_dat_vec_obs <- dat_vec_obs[dat_vec_obs <1 & dat_vec_obs >0]
  # small_dat_vec_preds <- dat_vec_preds[dat_vec_preds <1 & dat_vec_preds >0]
  op1_obs <- small_dat_vec_obs
  op2_obs<- 1-small_dat_vec_obs
  # op1_preds <- small_dat_vec_preds
  # op2_preds <- 1-small_dat_vec_preds
  
  ## minimum of op1 op2
  delt_obs <- min(c(op1_obs,op2_obs))
  # delt_preds <- min(c(op1_preds,op2_preds))
  
  ## getting set of frequencies
  freqs_obs <- NULL
  for(i in 1:length(dat_vec_obs)){
    if(dat_vec_obs[i] <= delt_obs){
      freqs_obs[i] <- delt_obs/2
    }else if(dat_vec_obs[i] >= 1- delt_obs){
      freqs_obs[i] <- 1-(delt_obs/2)
    }else{
      freqs_obs[i] <-dat_vec_obs[i]
    }
  }
  
 # freqs_preds <- NULL
 # for(i in 1:length(dat_vec_preds)){
 #   if(dat_vec_preds[i] <= delt_preds){
 #     freqs_preds[i] <- delt_preds/2
 #   }else if(dat_vec_preds[i] >= 1- delt_preds){
 #     freqs_preds[i] <- 1-(delt_preds/2)
 #   }else{
 #     freqs_preds[i] <-dat_vec_preds[i]
  #  }
 # }
  
  ##getting logits
  logits_obs <- log(freqs_obs/(1-freqs_obs))
  DFobsz[,new_nm] <- logits_obs
  
  # logits_preds <- log(freqs_preds/(1-freqs_preds))
  # DFpreds[,new_nm] <- logits_preds
}

DFobsz <- DFobsz %>%
  mutate(
    imp_w_pres = case_when(
    pct_imp_w_emplog <= -8.111428 ~ 0,
    pct_imp_w_emplog > -8.111428 ~1
  )
)

head(DFobsz$imp_w_pres)
head(DFobsz$pct_imp_w)

names(DFobsz)
DFobsz2 <- dplyr::select(DFobsz, c(station_id_2, pct_for_w_emplog:imp_w_pres))
# put transformed covariates in an SF object
DFobs2a <- full_join(DFobs2, DFobsz2, by = join_by(station_id_2))

# put SF object into SSN
j_ssn3 <-  SSN2::ssn_put_data(DFobs2a,j_ssn3)

# dummy code 5 vahusb with base being JU, James Upper
vahusb <- dplyr::select(DFobsz, vahusb)
summary(vahusb)
glimpse(vahusb)

vahusb_d <- (data.frame(dummy(vahusb)))
# 5 levels need only n-1 =4 dummy variables, removed base level of JU by dropping first column
vahusb_d <- vahusb_d[c(-1)]
dim(vahusb_d)
head(DFobsz$vahusb)
distinct(vahusb_d)
head(vahusb_d)
str(vahusb_d)
class(vahusb_d)

DFobsz <- cbind(DFobsz,vahusb_d)
names(DFobsz)

X1 <- DFobsz|>
   dplyr::select(station_id_2, vahusb_JM, vahusb_JR, vahusb_JA, vahusb_JL) %>%
  mutate_at(c('vahusb_JM', 'vahusb_JR', 'vahusb_JA', 'vahusb_JL'), as.numeric)
# X1 can only contain numeric or factor

str(X1)

# put dummy covariates in an SF object
DFobs3a <- full_join(DFobs2a, X1, by = join_by(station_id_2))
names(DFobs3a)

# put SF object into SSN
j_ssn3 <-  SSN2::ssn_put_data(DFobs3a,j_ssn3)
```

# 2.2 Transform Pred Covariates

Create station type, st_stype, noting that 34 preds are status stations with a single observation. Have 7 trends stations with 2 measurements for a total of 14 observations. Compare summaries of obs to preds to see if distributions overlap or if a pred value might be outside of the range of obs. The latter situation might identify a potential extrapolation or outlier.
```{r transform_preds_stationtype}
# did this assignment so would not have to change all the object names below
preds3 <- preds1

# create same name as in obs models
preds3$tothab <- preds3$tot_hab
summary(preds3$tothab)
summary(DFobs3a$tothab)

preds3 <- preds3 %>%
  mutate(
    st_type = case_when(
    station_id ==  station_id_2 ~ "status",
    station_id != station_id_2 ~ "trend"
  )
)

summary(as.factor(preds3$st_type))

preds3$vsci <- round(preds3$vscivcpmi,1)
summary(preds3$vsci)

ggplot(preds3, aes(x = st_type, y = vsci)) + geom_boxplot() + labs(title = "Preds 2019-2022 (n=48)")

select(preds3, station_id_2, st_type, vsci) %>% arrange(st_type, station_id_2, vsci) %>% print(n =Inf)

preds3 %>%
  group_by(st_type) %>%
  summarize(min = fivenum(vsci)[1],
            low = fivenum(vsci)[2],
            median = fivenum(vsci)[3],
            mean = mean(vsci, na.rm = TRUE),
            upper = fivenum(vsci)[4],
            max = fivenum(vsci)[5],
            count = dplyr::n()) %>%
  print(n = Inf)

DFobs3a %>%
  group_by(st_type) %>%
  summarize(min = fivenum(vsci)[1],
            low = fivenum(vsci)[2],
            median = fivenum(vsci)[3],
            mean = mean(vsci, na.rm = TRUE),
            upper = fivenum(vsci)[4],
            max = fivenum(vsci)[5],
            count = dplyr::n()) %>%
  print(n = Inf)
```

Creating subbasin factors and logging total nitrogen.
```{r }
preds3$year_f <- as.factor(preds3$year)
preds3$vahusb <- factor(preds3$vahusb, levels = c("JU", "JM", "JR", "JA", "JL"))
summary(preds3$vahusb)

preds3 <- preds3 %>%
  mutate(
    jl = case_when(
    vahusb != "JL" ~ 0,
    vahusb == "JL" ~1
  )
)

preds3 <- preds3 %>% 
  mutate(
    ju = case_when(
      vahusb == "JU" ~ "yes",
      .default = "no"
    )
  )
preds3$ju <- factor(preds3$ju, levels = c("yes","no"))
summary(preds3$ju)


preds3$l_tn <- log(preds3$tn)
summary(preds3$l_tn)
summary(DFobs3a$l_tn)

```

Wastewater treatment plants and statsgo2 covariates for preds
```{r wwtp_preds}
# WWTP data loaded from obs so comment  out
# wwtp_ds1 <- read.csv("E:/R_vdeq_nhdplus/WWTP_VA.csv") %>% clean_names(.)

preds3 <- left_join(preds3, wwtp_ds1, by = join_by(feature_id == comid))

preds3 <- preds3 %>% 
  mutate(
    wwtp = case_when(
      wwtp_all_dens_ws > 0 ~ "yes",
      wwtp_all_dens_ws == 0 ~ "no"
    )
  )

preds3$wwtp <- factor(preds3$wwtp, levels = c("yes","no"))
summary(preds3$wwtp)

# loaded from obs so commented out
# Statgo2 Set 2 variables, use RckDepWs
#statsgo_set2 <- read.csv("E:/R_vdeq_nhdplus/STATSGO_Set2_VA.csv") %>% clean_names(.)

names(statsgo_set2)

preds3 <- left_join(preds3, statsgo_set2, by = join_by(feature_id == comid))
```

Waterbody dat for preds.
```{r preds_waterbody}
# Preds Waterbody data
preds1wb_ds1 <- read.csv("data/PredictionPoints_2019_2020_DistancesUpstream_091924.csv") %>% clean_names(.)

preds2wb_ds1 <- read.csv("data/PredictionPoints_2021_2022_DistancesUpstream_091924.csv") %>% clean_names(.)

predsallwb_ds1 <- bind_rows(preds1wb_ds1, preds2wb_ds1)

class(predsallwb_ds1)
names(predsallwb_ds1)
head(predsallwb_ds1)
str(predsallwb_ds1)
summary(predsallwb_ds1$num_waterbody_up, na.rm = TRUE)
summary(predsallwb_ds1$dist_nearest_up_wb_km, na.rm = TRUE)
predsallwb_ds1$dist_nearest_up_wb_km <- round(predsallwb_ds1$dist_nearest_up_wb_km, 1)

summary(predsallwb_ds1$dist_nearest_up_wb_km, na.rm = TRUE)

summary(predsallwb_ds1$dist_nearest_up_wb_km)

predsallwb_ds1$dist_nearest_up_wb_km[is.na(predsallwb_ds1$dist_nearest_up_wb_km)] <- 0

summary(predsallwb_ds1$dist_nearest_up_wb_km)
summary(DFobs3a$dist_nearest_up_wb_km)

# station_id_2 and station_id are both long station trend names
preds3 <- left_join(preds3, predsallwb_ds1, by = join_by(station_id_2 == station_id))
names(preds3)

preds3 <- preds3 %>% 
  mutate(
    wbc = case_when(
      incl_nhdwb == "yes" ~ "present",
      incl_nhdwb != "yes" ~ "absent"
    )
  )

preds3$wbc <- factor(preds3$wbc, levels = c("present", "absent"))
summary(preds3$wbc)

preds3 <- preds3 %>% 
  mutate(
    wbc_bin = case_when(
      incl_nhdwb == "yes" ~ 1,
      incl_nhdwb != "yes" ~ 0
    )
  )

preds3$wbc_bin <- as.numeric(preds3$wbc_bin)

names(preds3)

class(preds3)
# note ssn_put_data requires sf object and SSN2 object
j_ssn3 <-  SSN2::ssn_put_data(preds3,j_ssn3, name = "Preds_2019_2022", resize_data = FALSE)
summary(j_ssn3)

# saveRDS(j_ssn3, file = "j_ssn3.rds")

```

Empirical logit transformation for preds.
```{r empirical_logit_preds}
# VARIABLE ADJUSTMENT ZONE 4
### Variables to apply empirical logit transformation
# emplog_vars <- c("pct_for_w","pct_imp_w","pct_crop_w","pct_hay_w","pct_grs_w","pct_shrb_w","pct_for_wr","pct_imp_rp_w","pct_crop_wr","pct_hay_wr","pct_grs_wr","pct_shrb_wr","pct_for_c","pct_imp_c","pct_crop_c","pct_hay_c","pct_grs_c", "pct_shrb_c", "pct_for_cr","pct_imp_rp_c","pct_crop_cr","pct_hay_cr","pct_grs_cr","pct_shrb_cr")

# remove geometry so empirical logit can be applied
predsz <- st_set_geometry(preds3, NULL)
################################################################
################################################################


## transform these variables and put the new values into new columns in preds
for(var in emplog_vars){
  ### create new tranformed data column to preserve the original
  new_nm <- paste0(var,"_emplog")
  dat_vec_obs <- predsz[,var]
  # dat_vec_preds <- DFpreds[,var]
  
  #converting to 0-1 range
  dat_vec_obs <- dat_vec_obs/100
  # dat_vec_preds <- dat_vec_preds/100
  
  # dat_vec[dat_vec == 1] <- .9999
  # dat_vec[dat_vec == 0] <- .0001
  
  if(any(dat_vec_obs > 1 | dat_vec_obs < 0)){
    cat("ERROR: percentage variables outside logical bounds")
  }
  
  small_dat_vec_obs <- dat_vec_obs[dat_vec_obs <1 & dat_vec_obs >0]
  # small_dat_vec_preds <- dat_vec_preds[dat_vec_preds <1 & dat_vec_preds >0]
  op1_obs <- small_dat_vec_obs
  op2_obs<- 1-small_dat_vec_obs
  # op1_preds <- small_dat_vec_preds
  # op2_preds <- 1-small_dat_vec_preds
  
  ## minimum of op1 op2
  delt_obs <- min(c(op1_obs,op2_obs))
  # delt_preds <- min(c(op1_preds,op2_preds))
  
  ## getting set of frequencies
  freqs_obs <- NULL
  for(i in 1:length(dat_vec_obs)){
    if(dat_vec_obs[i] <= delt_obs){
      freqs_obs[i] <- delt_obs/2
    }else if(dat_vec_obs[i] >= 1- delt_obs){
      freqs_obs[i] <- 1-(delt_obs/2)
    }else{
      freqs_obs[i] <-dat_vec_obs[i]
    }
  }
  
 # freqs_preds <- NULL
 # for(i in 1:length(dat_vec_preds)){
 #   if(dat_vec_preds[i] <= delt_preds){
 #     freqs_preds[i] <- delt_preds/2
 #   }else if(dat_vec_preds[i] >= 1- delt_preds){
 #     freqs_preds[i] <- 1-(delt_preds/2)
 #   }else{
 #     freqs_preds[i] <-dat_vec_preds[i]
  #  }
 # }
  
  ##getting logits
  logits_obs <- log(freqs_obs/(1-freqs_obs))
  predsz[,new_nm] <- logits_obs
  
  # logits_preds <- log(freqs_preds/(1-freqs_preds))
  # DFpreds[,new_nm] <- logits_preds
}

predsz <- predsz %>%
  mutate(
    imp_w_pres = case_when(
    pct_imp_w_emplog <= -8.111428 ~ 0,
    pct_imp_w_emplog > -8.111428 ~1
  )
)

head(predsz$imp_w_pres)
head(predsz$pct_imp_w)
names(predsz)
predsz2 <- dplyr::select(predsz, c(station_id_2, pct_for_w_emplog:imp_w_pres))
# put transformed covariates in an SF object
preds3a <- full_join(preds3, predsz2, by = join_by(station_id_2))
summary(preds3a$pct_imp_w_emplog)
class(preds3a)

# saveRDS(preds3a, file = "preds3a.rds")

# put SF object into SSN
j_ssn3 <-  SSN2::ssn_put_data(preds3a,j_ssn3, name = "Preds_2019_2022", resize_data = FALSE)
summary(j_ssn3$preds$Preds_2019_2022$pct_imp_w_emplog)
summary(j_ssn3$obs$pct_imp_w_emplog)

summary(j_ssn3$preds$Preds_2019_2022$pct_imp_w)
summary(j_ssn3$obs$pct_imp_w)
```

Dummy code for preds
```{r dummycode_preds}
# dummy code 5 vahusb with base being JU, James Upper
vahusb <- dplyr::select(predsz, vahusb)
summary(vahusb)
glimpse(vahusb)

vahusb_d <- (data.frame(dummy(vahusb)))
# 5 levels need only n-1 =4 dummy variables, removed base level of JU by dropping first column
vahusb_d <- vahusb_d[c(-1)]
dim(vahusb_d)
head(predsz$vahusb)
distinct(vahusb_d)
head(vahusb_d)
str(vahusb_d)
class(vahusb_d)

predsz <- cbind(predsz,vahusb_d)
names(predsz)

P1 <- predsz|>
   dplyr::select(station_id_2, vahusb_JM, vahusb_JR, vahusb_JA, vahusb_JL) %>%
  mutate_at(c('vahusb_JM', 'vahusb_JR', 'vahusb_JA', 'vahusb_JL'), as.numeric)
str(P1)

# P1 can only contain numeric or factor for 22 preds

# put dummy covariates in an SF object
preds3b <- full_join(preds3a, P1, by = join_by(station_id_2))
names(preds3b)

# put SF object into SSN
j_ssn3 <-  SSN2::ssn_put_data(preds3b,j_ssn3, "Preds_2019_2022", resize_data = FALSE)

summary(j_ssn3)

# Check that afv_area is in SSN object
str(j_ssn3$preds$Preds_2019_2022$afv_area)
```

# 3.0 Create Distance Matrix

When using a new SSN object, such as James_071024_pluspreds.ssn have to create distance matrices. Ran first set of code and now see a distance matrix folder in where the SSN object is stored at:
ssn_object/James_071024_pluspreds.ssn and see sub folders for obs and Preds_2019_2022 subfolder.
Already ran this code so it is commented out.
```{r distance_matrix}

# Distance matrix for obs and first set of prediction points from 2019-2022
# SSN2::ssn_create_distmat(j_ssn3, predpts = "Preds_2019_2022", overwrite = TRUE)

```



# 4.0 Ws-Wq Model
This is the SSN Ws-Wq model that was evaluated in script 05. Here is it run again and augmented with diagnostic and fitted values. The parallel coordinate plot of the augmented data frame was grouped by the 5 vahusb. The clustering of the JU variables in that plot is what suggested using the partition factor. See also, the NMC Elevation Boxplots under Figures for Presentation. See the description of partition factor under section 4.1.3 Advanced Features in An Introduction to Spatial Stream Network Modeling in R using SSN2.

The ssn_wswq is the base model, and subsequent models derived from the base model will be preceded by prefix and underscore to identify the essential purpose or hypothesis of the new model.

```{r wswq_ssn_obs_fitted}
ssn_wswq_reml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "reml",
  additive = "afv_area"
)
summary(ssn_wswq_reml1)
varcomp(ssn_wswq_reml1)
loocv(ssn_wswq_reml1)

#plot(ssn_wswq_reml1, which = c(1:6))

tidy(ssn_wswq_reml1)

```

## 4.1 Mapview Standardized Residuals
Here the augment function is applied the SSN model, and this creates an sf object that has the following diagnostics variables: .fitted for fitted values; .resid for response residuals; .hat for leverage, .cooks for Cook's distance, .std.resid for standaredized residuals, and .se.fit for standard error of the fitted values. 

In a spatial model (which includes spatial stream network models), residuals are spatially autocorrelated, so it is more helpful to apply typical model diagnostics to the standardized residuals, which have been decorrelated. The map below of standardized residuals can give a spatial characterization. Are extreme values of the standardized residuals spread throughout the spatial domain, or is there a geographic clustering of extreme standardized residuals? A clustering might indicate a locality that other covariates should be considered.
```{r mapview_wswq_ssn_residuals}
aug_ssn_wswq_reml1 <- augment(ssn_wswq_reml1, drop = FALSE)
class(aug_ssn_wswq_reml1)

summary(aug_ssn_wswq_reml1$.std.resid)

mapview(aug_ssn_wswq_reml1, zcol = ".std.resid", alpha.regions = .8, legend = TRUE, popup = popupTable(aug_ssn_wswq_reml1, zcol = c(".std.resid")))

```

## 4.2 Parallel Coordinates Plot of Covariates by Subbasin
A parallel coordinates plot standardizes all the variables, and when grouped, such as be subbasins, lets one see if subbasins have similar or dissimilar values. The elevation pattern for JU shown in the parallel coordinates plot motivated the idea of using the partition factor.
```{r pcp_covariates_subbasin}
# names(aug_ssn_wswq_reml1)
pcpobs <- ggparcoord(data = aug_ssn_wswq_reml1, columns = c(123, 136, 38, 167), groupColumn = "vahusb", scale = "std", showPoint = TRUE, title = "Observed Sites", alphaLines = 0.8, boxplot = FALSE)
pcpobs

```

# 5.0 Partitioned Ws-Wq Model
Note the nomenclature of this model is p_ssn_wswq_rem1 with the p indicating the partitioning factor.

The p_ssn_wswq model below has the partitioned factor of ju, Upper James versus the 4 lower subbasins. What the partition factor is doing is saying the observations in the Upper James are uncorrelated, or indepedent, from the observations in the lower 4 subbasins. You can think of the partition factor as the "Las Vegas Effect". What happens in Vegas stays in Vegas. Likewise, what spataily occurs in the Upper James stays in the Upper James.
```{r wswq_ssn_partition}

p_ssn_wswq_reml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "reml",
  additive = "afv_area",
  partition_factor = ~ ju
)
summary(p_ssn_wswq_reml1)
varcomp(p_ssn_wswq_reml1)
loocv(p_ssn_wswq_reml1) %>% print(n = Inf)

glances(ssn_wswq_reml1,p_ssn_wswq_reml1)

# plot(p_ssn_wswq_reml1, which = c(1:6))

tidy(p_ssn_wswq_reml1)
```
 
## 5.1 Mapview Standardized Residuals
```{r mapview aug_p_wswq_reml1}
aug_p_wswq_reml1 <- augment(p_ssn_wswq_reml1, drop = FALSE)
summary(aug_p_wswq_reml1$.std.resid)

mapview(aug_p_wswq_reml1, zcol = ".std.resid",  alpha.regions = .8, legend = TRUE, popup = popupTable(aug_p_wswq_reml1, zcol = c(".std.resid"))) 

```

## 5.2 p_WsWq SSN Model:  ML Estimation
Because we want to compare p_WsWq SSN model fit and predictions to models with different covariates, see additional hypotheses model in section 6.0, we need to  specify estimation method as ml.
```{r p_ssn_wswq_ml}
p_ssn_wswq_ml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "ml",
  additive = "afv_area",
  partition_factor = ~ ju
)
summary(p_ssn_wswq_ml1)
varcomp(p_ssn_wswq_ml1)
loocv(p_ssn_wswq_ml1) %>% print(n = Inf)

```


# 6.0 Additional Hypotheses for Ws-Wq SSN model
The partitioned model, using ML estimation, beat out the additional hypotheses model based on AICc, RMSPE, and cor2. See Ver Hoef et al. 2014 for description of using ML estimation when comparing models with different covariates.

```{r additional_hypotheses}

a_ssn_wswq_ml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + rck_dep_ws + wwtp + wbc,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "ml",
  additive = "afv_area",
  partition_factor = ~ju
)
summary(a_ssn_wswq_ml1)
varcomp(a_ssn_wswq_ml1)
loocv(a_ssn_wswq_ml1) %>% print(n = Inf)

glances(p_ssn_wswq_ml1,a_ssn_wswq_ml1)
loocv(a_ssn_wswq_ml1)

# plot(a_ssn_wswq_ml1, which = c(1:6))

# tidy(a_ssn_wswq_ml1)
```

## 6.1 Mapview Standardized Residuals
```{r mapview_a_ssn_wswq_reml1}
# inserted r in file name to indicate residuals now included
a_rssn_wswq_ml1 <- augment(a_ssn_wswq_ml1, drop = FALSE)

summary(a_rssn_wswq_ml1$.std.resid)

mapview(a_rssn_wswq_ml1, zcol = ".std.resid",  alpha.regions = .8, legend = TRUE, popup = popupTable(a_rssn_wswq_ml1, zcol = c(".std.resid"))) 


```

# 7.0 Distance Hypothesis for WsWq SSN Model
Here we use the distance covariate to test the hypothesis that monitoring sites having upstream waterbodies furthest away would have higher VSCI.

There are 4 parts to this section:  a) exploratory spatial data analysis, b) diagnostics on the non-spatial model, c) ML estimation of d_ssn_wswq_ml1 for comparison to ssn models with other covaries, and d) REML estimation, d_ssn_wswq_reml1 that would be used for prediction. 

The d_ssn_wswq_ml1 beats the p_ssn_wswq_ml1 model both on model fit, having a smaller AICc, and model performance, smaller rmspe and larger cor2.

## 7.1 ESDA on Distance Hypothesis
Running torgegram on SSN0 nugget mlr model as shown in section 4.1.1 of SSN2 vignette. Not seeing much in Torgegram plot.
```{r esda_distance_hypothesis}

ggplot(DFobs3a, aes(x = dist_nearest_up_wb_km, y = vsci)) + geom_point() + facet_wrap(vars(wbc))  + geom_smooth(method = "lm", se =TRUE)

ggplot(DFobs3a, aes(x = dist_nearest_up_wb_km, y = vsci)) + geom_point() + geom_smooth(method = "lm", se =TRUE)

d_tg <- Torgegram(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km,
  ssn.object = j_ssn3,
  type = c("flowcon", "flowuncon", "euclid")
)
plot(d_tg)
plot(d_tg, separate = TRUE)
View(d_tg$euclid)
View(d_tg$flowuncon)  
View(d_tg$flowcon) # low np
```

## 7.2 Check Nonspatial Diagnostics on Distance MLR Model
Get checks on collinearity, added variable plots and other diagnostics. Typical MLR diagnostics look good. 
```{r a5_mlr_diagnostics}
d_mlr1 <- lm(vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km,
  data = DFobs3a)

summary(d_mlr1)
check_model(d_mlr1)
avPlots(d_mlr1)
```

## 7.3 d_ssn_wswq_ml1
```{r d_ssn_wswq_ml1}
d_ssn_wswq_ml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "ml",
  additive = "afv_area",
  partition_factor = ~ju
)

summary(d_ssn_wswq_ml1)
varcomp(d_ssn_wswq_ml1)
loocv(d_ssn_wswq_ml1)
tidy(d_ssn_wswq_ml1)

# plot(d_ssn_wswq_reml1, which = c(1:6))

glances(p_ssn_wswq_ml1,d_ssn_wswq_ml1)

```

## 7.4 d_ssn_wswq_reml1
The reml estimation method is the one we want to use for obtaining variance composition from the varcomp function and for making predictions.
```{r d_ssn_wswq_ml1}
d_ssn_wswq_reml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "reml",
  additive = "afv_area",
  partition_factor = ~ju
)

summary(d_ssn_wswq_reml1)
varcomp(d_ssn_wswq_reml1)
loocv(d_ssn_wswq_reml1)

tidy(d_ssn_wswq_reml1)

# plot(d_ssn_wswq_reml1, which = c(1:6))

```

## 7.5 Ribbon LOOCV Fitted Interval
This diagnostic plot takes the 199 fitted values from the leave-one-out cross validation of d_ssn_wswq_reml1, plots them on the x-axis and the199  observed vsci values on the y-axis and so indicates the correlation between these two values. Because the loocv function returns the standard error of the fit, se.fit, we can calculated a 90% fitted interval by specifying the z-statistics  of 1.645 in the geom_ribbon argument of the ggplot function. This diagnostic plot offers 3 "gut checks" on our model:  1) do we see a linear relationship between fitted and observed? 2) How many points fall outside the fitted interval? If it is a lot of points then that suggests the model is not fitting the data well. 3) Do the points falling outside the fitted interval cluster around certain values? Such a clustering might indicate that the model is not fitting well.

The reference to ribbon is because the `geom_ribbon` argument is used to make the plot.
```{r ribbon_loocv_fitted_interval}
cv_resids = loocv(d_ssn_wswq_reml1,
                  cv_predict = T,
                  se.fit = T)


spat_loocv1 <- cbind(cv_resids$cv_predict, cv_resids$se.fit, DFobs3a$vsci)
colnames(spat_loocv1) <- c("cv_predict", "se.fit", "vsci")

spat_loocv1 <- as.data.frame(spat_loocv1)
head(spat_loocv1)

spat_loocv1$cv_predict <- round(spat_loocv1$cv_predict,1)

station_id_2 <-dplyr::select(DFobs3a,station_id_2)

# put sf object first so sticky geometry retained
spat_loocv2 <- bind_cols(station_id_2, spat_loocv1)

# 90% loocv fitted limits b/c z-statistics 1.645 used
ggplot(spat_loocv2, aes(x = cv_predict, y = vsci)) + geom_point() + geom_abline() + geom_ribbon(aes(ymin = cv_predict - (1.645*se.fit), ymax = cv_predict + (1.645*se.fit)), fill = "grey", alpha = .8) + geom_line(aes( y = cv_predict)) + labs(x = "VSCI LOOCV Fitted 2001-2018", y = "VSCI Observed 2001-2018", title = "SSN LOOCV Obs vs Fitted d_ssn_wswq_reml1 n=199")

cor(spat_loocv2$cv_pred,spat_loocv2$vsci, method = "pearson")

# number of points outside 90% loocv fitted limits (ofl) 
ofl_stations1 <- filter(spat_loocv2, vsci < (cv_predict - (1.645*se.fit)) | vsci > (cv_predict + (1.645*se.fit)))
ofl_stations1 %>% print(n = Inf)

mapview(ofl_stations1)

edges <- st_read("ssn_object/James_071024_pluspreds.ssn/edges.shp")

# now see 2 trend stations on Tye River
# when zoom in
# https://stackoverflow.com/questions/36469379/multiple-markers-on-same-coordinate
st_jitter(ofl_stations1, factor = 0.001) %>% 
  mapview(., col.regions = "red") + mapview(edges)



```

## 7.6 Mapview Standardized Residuals
The scatter plot above gave a statistical characterization of observed and fitted values. The map below of standardized residuals can give a spatial characterization. Are extreme values of the standardized residuals spread throughout the spatial domain, or is there a geographic clustering of extreme standardized residuals? A clustering might indicate a locality that other covariates should be considered.

```{r mapview aug_d_wswq_reml1}
aug_d_wswq_reml1 <- augment(d_ssn_wswq_reml1, drop = FALSE)
summary(aug_d_wswq_reml1$.std.resid)

mapview(aug_d_wswq_reml1, zcol = ".std.resid",  alpha.regions = .8, legend = TRUE, popup = popupTable(aug_d_wswq_reml1, zcol = c(".std.resid"))) 

```


# 8.0 Status and Trend WsWq SSN model
The status stations have single observation whereas trend stations have repeated observations made over several years.

Using a more complex model, st_ssn_wswq_rand1, with a covariate of station type, status versus trend, and a random effect for repeated observations at trend stations, does not produce a better fitting or predictive model compared to the distance SSN model.


```{r st_vs_distance}
st_ssn_wswq_rand1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km + st_type,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "ml",
  additive = "afv_area",
  partition_factor = ~ju,
  random = ~ (1 | station_id)
)

summary(st_ssn_wswq_rand1)
varcomp(st_ssn_wswq_rand1)
loocv(st_ssn_wswq_rand1)

# plot(st_ssn_wswq_rand1, which = c(1:6))

glances(d_ssn_wswq_ml1, st_ssn_wswq_rand1)


```

# 9.0 NMC Distance Model w/ and w/o Partition Factor
This compares the distance SSN model from section 7, which has a partition factor, to a distance model with no partition factor. The better model is the distance SSN model with the partition factor. This result was used in the NMC 2025 presentation.

Because the partition factor affects the covariance matrix I use REML estimation for model comparison. See Details of partition factor in the help of the ssn_lm function.
```{r distance_with_without_partition}
#np stands for no partition factor

np_ssn_wswq_reml1 <- ssn_lm(
  formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL + dist_nearest_up_wb_km,
  ssn.object = j_ssn3,
  tailup_type = "none",
  taildown_type = "exponential",
  euclid_type = "exponential",
  nugget_type = "nugget",
  estmethod = "reml",
  additive = "afv_area"
)


summary(np_ssn_wswq_reml1)
varcomp(np_ssn_wswq_reml1)
loocv(np_ssn_wswq_reml1)
tidy(np_ssn_wswq_reml1)

glances(d_ssn_wswq_reml1, np_ssn_wswq_reml1)
```


# 10 Predictands from Distance WsWQ SSN Model
Now we want to d_ssn_wswq_reml1 as the ssn model to get predictions for the independent 48 observations from 2019-2022.

Note we are using the augment function again, but this time is used with ssn_lm, d_ssn_wswq_reml1, plus specifying the new data of the prediction points. After getting the predictions, we 1) examine the 48 predictions, 2) plot them against their observed, or "true" values of vsci and 3) calculate a correlation between the true values and predicted values.
```{r distance_hypothesis_preds}

# augment returns an sf object
# note level set to 0.90
aug_d_predict1ws_vsci <- augment(d_ssn_wswq_reml1, newdata = "Preds_2019_2022", se_fit = TRUE, interval = c("prediction"), level = 0.90)
# class(aug_a5predict1ws_vsci)
# names(aug_a5predict1ws_vsci)
aug_d_predict1ws_vsci$vsci_pred <- round(aug_d_predict1ws_vsci$.fitted,1)
aug_d_predict1ws_vsci$vsci_lwr <- round(aug_d_predict1ws_vsci$.lower,1)
aug_d_predict1ws_vsci$vsci_upr <- round(aug_d_predict1ws_vsci$.upper,1)
head(aug_d_predict1ws_vsci$.se.fit)
# Pineiro 2008 put observed on y and predict on x
# label specific points
# https://stackoverflow.com/questions/15624656/label-points-in-geom-point

select(aug_d_predict1ws_vsci, station_id_2, st_type, vsci, vsci_pred, .se.fit) %>% arrange(.se.fit) %>% print(n =48)

ggplot(aug_d_predict1ws_vsci, aes(x = vsci_pred, y = vsci, size = .se.fit, shape = st_type, color = st_type)) + geom_point() + labs(x = "Predicted VSCI", y = "True VSCI, 2019-2022", title = "SSN Prediction Sites", shape = "Station Type", color = "Station Type") + xlim(35,80) + ylim(35,80) + scale_size_binned(name = "Standard Error") + guides(color = guide_legend(override.aes = list(size = 6))) + theme(legend.text = element_text(size = 12))

cor(aug_d_predict1ws_vsci$vsci_pred,aug_d_predict1ws_vsci$vsci, method = "pearson")

# note that squaring the correlation corresponds to cor2 from the loocv function
cor(aug_d_predict1ws_vsci$vsci_pred,aug_d_predict1ws_vsci$vsci, method = "pearson")^2

as.data.frame(aug_d_predict1ws_vsci)|>
  dplyr::select(vsci_pred,vsci)|>
  correlate()


```

# 11 Interactive Mapping of Predictands
With spatial data analysis, we are interested in two distributions. One is the statistical distribution, such as the correlation above, and the other is the spatial distribution. For example, are there regions, or subbasins, with outliers?

## 11.1 VAHUSB Polygons
Slight edits to vahusb polygons to make for better maps.
```{r vahusb_poly}
vahusb_poly <- sf::st_read("data/vahusb.shp")
# names(vahusb_poly)
# mapview(vahusb_poly)
mapview(vahusb_poly, zcol="VAHUSB", burst = TRUE)

vahusb_poly <- vahusb_poly %>% 
  mutate(
    subbasin = case_when(
      VAHUSB == "James River, Upper (Mountain)" ~ "JU",
      VAHUSB == "James River, Middle (Piedmont)" ~ "JM",
      VAHUSB == "James River- Rivanna River" ~ "JR",
      VAHUSB == "James River- Appomattox River" ~ "JA",
      VAHUSB == "James River, Lower (Tidal)" ~ "JL"
    )
  )
names(vahusb_poly)
mapview(vahusb_poly, zcol="subbasin", burst = TRUE)

vahusb_poly$subbasin <- factor(vahusb_poly$subbasin, levels = c("JU", "JM", "JR", "JA", "JL"))

# once made a factor do not need to do burst
mapview(vahusb_poly, zcol="subbasin")

```

## 11.2 Synced Maps
Synced maps are good for a quick, interactive visualization, but the workflow of make synced maps, use Rstudio export to save html locally, then open html in browser, snip a screenshot and paste into Powerpoint does not make publication-quality maps. I could not get the mapshot or mapshot2 functions in mapview to make a png.
```{r synced_maps}
names(DFobs3a)
names(aug_d_predict1ws_vsci)

vsci_obs <- mapview(DFobs3a, zcol = "vsci", at=seq(0, 90, 15), alpha.regions = .8, legend = TRUE,layer.name = 'Observed Sites VSCI', popup = popupTable(aug_d_predict1ws_vsci, zcol = c("station_id_2", "vsci"))) + mapview(vahusb_poly, zcol="subbasin")
vsci_obs

vsci_true <- mapview(aug_d_predict1ws_vsci, zcol = "vsci", at=seq(0, 90, 15), alpha.regions = .8, legend = TRUE,layer.name = 'Prediction Sites True VSCI', popup = popupTable(aug_d_predict1ws_vsci, zcol = c("station_id_2", "vsci"))) + mapview(vahusb_poly, zcol="subbasin")

vsci_true

print(sync1 <- sync(vsci_obs, vsci_true, ncol=1))


vsci_pred <- mapview(aug_d_predict1ws_vsci, zcol = "vsci_pred", at=seq(0, 90, 15), alpha.regions = .8, legend = TRUE,layer.name = 'Predictands VSCI', popup = popupTable(aug_d_predict1ws_vsci, zcol = c("station_id_2", "vsci_pred"))) + mapview(vahusb_poly, zcol="subbasin")

vsci_pred

print(sync2 <- sync(vsci_true, vsci_pred, ncol =1))

vsci_predse <- mapview(aug_d_predict1ws_vsci, zcol = ".se.fit",  alpha.regions = .8, legend = TRUE,layer.name = 'Predictands VSCI SE', popup = popupTable(aug_d_predict1ws_vsci, zcol = c("station_id_2", "st_type", "vsci", "vsci_pred", ".se.fit"))) + mapview(vahusb_poly, zcol="subbasin")

vsci_predse

print(sync3 <- sync(vsci_pred, vsci_predse, ncol=1))

```

# 12 Ribbon Predictand Interval
I call this a ribbon predictand interval graph simply because it uses the geom_ribbon function to easily make a prediction interval. This is producing a 90% prediction interval because that was the level set when augmented predictions were made. Ggplotly is used to identify observations falling outside of the prediction interval. Some observations, by chance, should follow outside the prediction interval. We want to investigate if there is a systematic basis why some might be outliers, such as local construction of ponds or a new point source close upstream.
```{r ribbon_pred_interval}

# ribbon using lower and upper SSN2 prediction intervals

ribbon_pi1 <- ggplot(aug_d_predict1ws_vsci, aes(x = vsci_pred, y = vsci, shape = st_type, color = st_type, label = station_id_2)) +   geom_point(aes(size = .se.fit)) + 
  geom_abline() + 
  geom_ribbon(aes(ymin = vsci_lwr, ymax = vsci_upr), fill = "grey", alpha = .4) + 
  geom_line(aes( y = vsci_pred)) + 
  labs(x = "Predicted VSCI", y = "TRUE VSCI 2019-2022", title = "SSN Predictions (prediction interval 0.90", subtitle = "Pearson Correlation = 0.57", shape = "Station Type", color = "Station Type") +
  scale_size_binned(name = "Standard Error") + guides(color = guide_legend(override.aes = list(size = 6))) + theme(legend.text = element_text(size = 12))

print(ribbon_pi1)
ggplotly(ribbon_pi1)

# opl stands for outside prediction limits
opl_stations2 <- filter(aug_d_predict1ws_vsci, vsci < vsci_lwr | vsci > vsci_upr)

class(opl_stations2)
mapview(opl_stations2, zcol = "station_id_2",  alpha.regions = .8, legend = TRUE,layer.name = 'Outside Prediction Limits', popup = popupTable(aug_d_predict1ws_vsci, zcol = c("station_id_2", "st_type", "vsci", "vsci_pred", ".se.fit"))) + mapview(vahusb_poly, zcol="subbasin")

opl_stations2
# given comment "Target and Sampled (no fish or PHAB in 2019?) Dry,no staff", should this site 2-DCK003.94_2019 been sampled?

```

# Figures for Presentations
## SFS 2024 Meeting Torgegram
```{r sfs_torgegram}

# torg2 <- ggplot(flowuncon, aes(x=dist, y=gamma)) + geom_point(size =3) + labs(x = "Flow-Unconnected Stream Distance (m)", y = "Semivariance", title = "VSCI Torgegram Stream Network Distance") + scale_x_continuous(labels=comma)
# png(file="figures_sfs/torg2.png",width=6,height=3,units="in",res=150)
#   torg2
# dev.off()


# esv2 <- ggplot(euclid, aes(x=dist, y=gamma)) + geom_point(size =3) + labs(x = "Euclidean Distance (m)", y = "Semivariance", title = "VSCI Semivariogram Euclidean Distance") + scale_x_continuous(labels=comma)
# png(file="figures_sfs_2024/esv2.png",width=6,height=3,units="in",res=150)
#   esv2
# dev.off()
```

# NMC 2025
## NMC True VSCI vs Pred VSCI Scatter Plot

```{r nmc_pred_true_vsci_stationtype}

a5preds2019_2022_v3 <- ggplot(aug_d_predict1ws_vsci, aes(x = vsci_pred, y = vsci, size = .se.fit, shape = st_type, color = st_type)) + geom_point() + labs(x = "Predicted VSCI", y = "True VSCI, 2019-2022", title = "SSN Prediction Sites", shape = "Station Type", color = "Station Type") + xlim(35,80) + ylim(35,80) + scale_size_binned(name = "Standard Error") + guides(color = guide_legend(override.aes = list(size = 6))) + theme(legend.text = element_text(size = 12))

png(file="figures_nmc_2025/a5preds2019_2022_v3.png",width=6,height=3,units="in",res=150)
a5preds2019_2022_v3
dev.off()

```

## NMC True VSCI vs Pred VSCI Ribbon Plot
```{r}
ribbon_pi1 <- ggplot(aug_d_predict1ws_vsci, aes(x = vsci_pred, y = vsci, shape = st_type, color = st_type, label = station_id_2)) + 
  geom_point(aes(size = .se.fit)) + 
  geom_abline() + 
  geom_ribbon(aes(ymin = vsci_lwr, ymax = vsci_upr), fill = "grey", alpha = .4) + 
  geom_line(aes( y = vsci_pred)) + 
  labs(x = "Predicted VSCI", y = "TRUE VSCI 2019-2022", title = "SSN Predictions (prediction interval 0.90)", subtitle = "Pearson Correlation = 0.57", shape = "Station Type", color = "Station Type") +
  scale_size_binned(name = "Standard Error") + guides(color = guide_legend(override.aes = list(size = 6))) + theme(legend.text = element_text(size = 12))

print(ribbon_pi1)
ggplotly(ribbon_pi1)

png(file="figures_nmc_2025/ribbon_pi1.png",width=6,height=3,units="in",res=150)
ribbon_pi1
dev.off()

```

## NMC Elevation Boxplots by Subbasin
```{r nmc_boxplots}
RColorBrewer::display.brewer.all()
viridis::viridis(7)
tmaptools::palette_explorer() # zoomed to this and checked options Print color values to get color codes for Brewer Categorical Set3 so I could specify fill colors to match tmaps

boxplot_elev_ws <- ggplot(data=DFobs3a, aes(y= elev_ws, x= vahusb)) + geom_boxplot(aes(fill = vahusb), outlier.shape = NA) + geom_jitter() + labs(y = "Watershed Elevation (m)", x = "Subbasins", fill = "Subbasin") + scale_fill_manual(values = c("#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3"))
  
png(file="figures_nmc_2025/boxplot_elev_ws_v1_20250225.png",width=6,height=3,units="in",res=150)
boxplot_elev_ws
dev.off()


```

## NMC tmap: Prediction Maps

```{r jprobmon}

legend_title = "Subbasin"
tm_shape(vahusb_poly) + tm_polygons("subbasin") +
  tm_layout(asp=0,
  legend.width = 2, legend.text.size = 1.5, legend.title.size = 3.0,
  frame = FALSE,
  legend.position = c("right", "TOP"),
  title.position = c('right', 'TOP')
) + tm_scale_bar(position = c("center", "BOTTOM", text.size = 1.0)) + tm_compass(position = c("left", "top")) +
  tm_legend(legend.outside=T,  legend.outside.position="top",legend.hist.height = 1.0, legend.hist.width = 1.0, legend.hist.size = 1.5)

# trying to make subasins legends only so can put in Powerpoint
sb_legend <- tm_shape(vahusb_poly) + tm_polygons("subbasin") +
  tm_layout(legend.only = TRUE)
tmap_save(sb_legend, "figures_nmc_2025/sb_legend.jpeg", width = 2, height = 2, dpi = 150)

# Observed sites
### doing legend.show = F for polygons as I will be placing sb_legend on Powerpoint

j_map_vsci_obs <- tm_shape(vahusb_poly) + tm_polygons("subbasin", legend.show = F) +
  tm_shape(DFobs3a) + 
  tm_bubbles(
  size = "vsci",
  legend.size.show = FALSE,
  col = "vsci",
  legend.col.is.portrait = FALSE,
  style = "fixed",
  palette = "viridis",
  title.col = "VSCI at Observed Sites 2001-2018 (n = 199)",
  breaks = seq(0, 90, by = 15),
  sizes.legend=seq(0, 90, by=15),
  legend.hist = FALSE,
) + tm_layout(asp=0,
  legend.width = 2, legend.text.size = 1.5, legend.title.size = 3.0,
  frame = FALSE,
  legend.position = c("center", "TOP"),
  title.position = c('center', 'TOP')
) + tm_scale_bar(position = c("center", "BOTTOM", text.size = 1.0)) + tm_compass(position = c("left", "top")) +
  tm_legend(legend.outside=T, legend.outside.position="top",legend.hist.height = 1.0, legend.hist.width = 1.0, legend.hist.size = 1.5)

tmap_save(j_map_vsci_obs, "figures_nmc_2025/j_map_vsci_obs_v1_20250212.jpeg", width = 7, height = 3.5, dpi = 150)

# map for true vsci predictands

j_map_vsci_true <- tm_shape(vahusb_poly) + tm_polygons("subbasin", legend.show = F) +
  tm_shape(aug_d_predict1ws_vsci) + 
  tm_bubbles(
  size = "vsci",
  legend.size.show = FALSE,
  col = "vsci",
  legend.col.is.portrait = FALSE,
  style = "fixed",
  palette = "viridis",
  title.col = "True VSCI at Prediction Sites 2019-2022 (n = 48)",
  breaks = seq(0, 90, by = 15),
  sizes.legend=seq(0, 90, by=15),
  legend.hist = FALSE,
) + tm_layout(asp=0,
  legend.width = 2, legend.text.size = 1.5, legend.title.size = 3.0,
  frame = FALSE,
  legend.position = c("center", "TOP"),
  title.position = c('center', 'TOP')
) + tm_scale_bar(position = c("center", "BOTTOM", text.size = 1.0)) + tm_compass(position = c("left", "top")) +
  tm_legend(legend.outside=T, legend.outside.position="top",legend.hist.height = 1.0, legend.hist.width = 1.0, legend.hist.size = 1.5)

tmap_save(j_map_vsci_true, "figures_nmc_2025/j_map_vsci_true_v1_20250212.jpeg", width = 7, height = 3.5, dpi = 150)


# map for vsci predictands

j_map_vsci_predicted <- tm_shape(vahusb_poly) + tm_polygons("subbasin", legend.show = F) +
  tm_shape(aug_d_predict1ws_vsci) + 
  tm_bubbles(
  size = "vsci_pred",
  legend.size.show = FALSE,
  col = "vsci_pred",
  legend.col.is.portrait = FALSE,
  style = "fixed",
  palette = "viridis",
  title.col = "Predictand VSCI at Prediction Sites 2019-2022 (n = 48)",
  breaks = seq(0, 90, by = 15),
  sizes.legend=seq(0, 90, by=15),
  legend.hist = FALSE,
) + tm_layout(asp=0,
  legend.width = 2, legend.text.size = 1.5, legend.title.size = 3.0,
  frame = FALSE,
  legend.position = c("center", "TOP"),
  title.position = c('center', 'TOP')
) + tm_scale_bar(position = c("center", "BOTTOM", text.size = 1.0)) + tm_compass(position = c("left", "top")) +
  tm_legend(legend.outside=T, legend.outside.position="top",legend.hist.height = 1.0, legend.hist.width = 1.0, legend.hist.size = 1.5)

tmap_save(j_map_vsci_predicted, "figures_nmc_2025/j_map_vsci_predictedv1_20250213.jpeg", width = 7, height = 3.5, dpi = 150)

# map for predictand se

j_map_vsci_predse <- tm_shape(vahusb_poly) + tm_polygons("subbasin", legend.show = F) +
  tm_shape(aug_d_predict1ws_vsci) + 
  tm_bubbles(
  size = ".se.fit",
  legend.size.show = FALSE,
  col = ".se.fit",
  legend.col.is.portrait = FALSE,
  style = "cont",
  palette = "viridis",
  title.col = "Standard Error of Predictand VSCI 2019-2022 (n = 48)",
  legend.hist = FALSE,
) + tm_layout(asp=0,
  legend.width = 2, legend.text.size = 1.5, legend.title.size = 3.0,
  frame = FALSE,
  legend.position = c("center", "TOP"),
  title.position = c('center', 'TOP')
) + tm_scale_bar(position = c("center", "BOTTOM", text.size = 1.0)) + tm_compass(position = c("left", "top")) +
  tm_legend(legend.outside=T, legend.outside.position="top",legend.hist.height = 1.0, legend.hist.width = 1.0, legend.hist.size = 1.5)

tmap_save(j_map_vsci_predse, "figures_nmc_2025/j_map_vsci_predse_v1_20250225.jpeg", width = 7, height = 3.5, dpi = 150)

```

# Neptune Code from TLH
This code is included for thoroughness, but does not need to be run unless user wants to see output.

Code from Neptune statistician, Travis Linscome-Hatfield, used base R plot code to make predictions versus observed plots. That base R code was replaced with SSN2 model output and ggplot2 code using geom_ribbon above to make prediction intervals for that plot.

# TLH fitted to obs interval plot
Commented out as uses base R plotting functions.
```{r fitted_interval_obs_plot}
# z4 model was run above

## fit model
# z4ssn_wswq_ml1 <- ssn_lm(
#   formula = vsci ~ pct_imp_w_emplog + elev_ws + do + vahusb_JL,
#   ssn.object = j_ssn3,
#   tailup_type = "none",
#   taildown_type = "exponential",
#   euclid_type = "exponential",
#   nugget_type = "nugget",
#   estmethod = "ml",
#   additive = "afv_area",
#   partition_factor = ~ju
# )
# summary(z4ssn_wswq_reml1)

# how do residuals and fitted values below compare to what comes out with augment function?



# class(aug_z4_wswq_reml1)
# names(aug_z4_wswq_reml1)
# 
# head(round(aug_z4_wswq_reml1$.fitted))
# head(round(aug_z4_wswq_reml1$vsci))


# get spatial residuals from model
# spatResids<-residuals(z4ssn_wswq_reml1)
# zspatResids<-residuals(z4ssn_wswq_reml1)
# head(aug_z4ssn_wswq_reml1$.resid)
# the three statements above all return same results

# pull sd of residuals and fitted values
# resid_SD = sd(spatResids)
# fitted_vals = z4ssn_wswq_reml1$fitted$response

# combine to a dataframe
# spat<-cbind(fitted_vals,resid_SD^2)
# head(spat)

# spatial prediction percentiles
# (spat.Pred.pct<-t(apply(spat,1,function(x) qnorm(c(Q05=0.05,Q10=0.1,Q25=0.25,Median=0.5,Q75=0.75,Q90=0.9,Q95=0.95),x[1],sqrt(x[2])))))

# spat.Pred.median = spat.Pred.pct[,4]
# head(spat.Pred.median)

# make sure I've got the right obj
# DFobs<-ssn_get_data(j_ssn3)
# observed and median of our prediction intervals
# ty<-DFobs$vsci
# tx<-spat.Pred.median

#percentiles
# ox<-order(tx)
# op05<-spat.Pred.pct[ox,"Q05"]
# op95 <- spat.Pred.pct[ox,"Q95"]

# plot
# plot(tx,ty,xlim=range(na.omit(tx)),ylim=range(na.omit(ty),na.omit(op95)),xlab="VSCI Predicted Value",ylab="VSCI Observed Value",main="Spatial Model Observed vs. Predicted z4 reml n = 199")
# abline(0,1,col="red")
# lines(lowess(na.omit(tx),na.omit(ty)),col='blue')

# 5th percentile of predictive distribution
# lines(tx[ox],op05,lty=2,col='black')
# 95th percentile of predictive distribution
# lines(tx[ox],op95,lty=2,col='black')
 #legend
# legend("topleft",lty=c(1,1,2,2),col=c("red","blue","black","black"),legend=c("y = x","lowess","5% Pred","95% Pred"), x.intersp = 0.7, y.intersp = 0.7)

# cor(tx,ty, method = "pearson")

# these object names are used again downstream for preds so remove here

# rm(spatResids,resid_SD,fitted_vals,spat,spat.Pred.pct,spat.Pred.median,ty,tx,ox,op05,op95)
```

# TLH fitted to obs interval plot (LOOCV method)
Commented out as uses base R plotting function. 
```{r fitted_interval_plot_loocv}
# Alrighty, so this method mimics John's method
# which gives a loocv estimate of fitted value an se.
# This results in the squiggly lines because he's giving that 
# se at each individual value.
# cv_resids = loocv(z4ssn_wswq_reml1,
 #                 cv_predict = T,
#                  se.fit = T)
# pull sd of residuals and fitted values
# resid_Se = cv_resids$se.fit
# fitted_vals = cv_resids$cv_predict

# combine to a dataframe
# spat<-cbind(fitted_vals,resid_Se^2)
# head(spat)

# spatial prediction percentiles
# (spat.Pred.pct<-t(apply(spat,1,function(x) qnorm(c(Q05=0.05,Q10=0.1,Q25=0.25,Median=0.5,Q75=0.75,Q90=0.9,Q95=0.95),x[1],sqrt(x[2])))))

# spat.Pred.median = spat.Pred.pct[,4]
# head(spat.Pred.median)

# make sure I've got the right obj
# DFobs<-ssn_get_data(j_ssn3)
# observed and median of our prediction intervals
# ty<-DFobs$vsci
# tx<-spat.Pred.median

#percentiles
# ox<-order(tx)
# op05<-spat.Pred.pct[ox,"Q05"]
# op95 <- spat.Pred.pct[ox,"Q95"]

# plot
# plot(tx,ty,xlim=range(na.omit(tx)),ylim=range(na.omit(ty),na.omit(op95)),xlab="VSCI Predicted Value",ylab="VSCI Observed Value",main="LOOCV Spatial Model Observed vs. Predicted z4 reml")
# abline(0,1,col="red")
# lines(lowess(na.omit(tx),na.omit(ty)),col='blue')

# 5th percentile of predictive distribution
# lines(tx[ox],op05,lty=2,col='black')
# 95th percentile of predictive distribution
# lines(tx[ox],op95,lty=2,col='black')
#legend
# legend("topleft",lty=c(1,1,2,2),col=c("red","blue","black","black"),legend=c("y = x","lowess","5% Pred","95% Pred"), x.intersp = 0.7, y.intersp = 0.7)

```
# Carson Code Points Outside LOOCV 90% Prediction Limit for n=199 Obs

This code comes from local_SSN_FINAL_20160126_modelling.html, which was written by John Carson, a statistician now at Neptune.
```{r loocv_pts_outside}
# number of points outside 90% prediction limits
# os90pl.sp <-(ty < spat.Pred.pct[,"Q05"]) |  (ty > spat.Pred.pct[,"Q95"]) 
# summary(os90pl.sp)

# which observations are outside [5%, 95%] prediction limits?
# these are the Site IDs of the unusual values
# DFobsz[which(os90pl.sp),"station_id_2"]
```

# TLH Exploring residuals and counts at trend vs status

While trend stations have smaller .se.fit than status stations, it appears this may simply be a function of more observations at trend stations than single-visit status stations with just 1 observation.
```{r}

## adding in some additional looks at .se.fit vs station type and number of samples.

# using preds data (n=48)
# create residuals in the new prediction frame as they don't provide from the prediction augment call
aug_d_predict1ws_vsci$.residuals <- aug_d_predict1ws_vsci$vsci-aug_d_predict1ws_vsci$.fitted


small_preds = aug_d_predict1ws_vsci%>% select(station_id_2,st_type,vsci,vsci_pred,.se.fit,.fitted,.residuals)

p = ggplot(small_preds, aes(x = .se.fit, y = .residuals,color = st_type))+
  geom_point(aes(label = station_id_2)) +
  labs(title = "Predictands .se.fit and .residual")
ggplotly(p,hoverinfo = "text")

filter(small_preds, st_type == "trend") %>% 
  select(station_id_2,st_type, .se.fit) %>% 
  arrange(station_id_2) %>% 
  print(n = Inf)

#small_preds n
small_preds_n = small_preds%>% group_by(station_id_2,st_type)%>% summarise(n = n())

# Using obs data (n=199)
## loocv
# already run in a chunk above aug_d_wswq_reml1 <- augment(d_ssn_wswq_reml1, drop = FALSE) to get .residual

# use loocv to get se.fit out of n = 199 obs

aug_d_wswq_reml1$se.fit <- loocv(d_ssn_wswq_reml1,se.fit = T)[[2]]
names(aug_d_wswq_reml1)

# small obs
small_obs = aug_d_wswq_reml1 %>% select(station_id_2,st_type,vsci,.fitted,.resid,se.fit)

p3 = ggplot(small_obs, aes(x = se.fit, y = .resid,color = st_type))+
  geom_point(aes(label = station_id_2)) +
  labs(title = "Observed loocv .se.fit and .residuals")
ggplotly(p3,hoverinfo = "text")

# is the .se.fit basically just based on number of samples?
small_obs_n = small_obs%>% select(station_id_2,st_type, se.fit)%>%
  group_by(station_id_2,st_type)%>%
  summarise(n = n()) 

filter(small_obs, st_type == "trend") %>% 
  select(station_id_2,st_type, se.fit) %>% 
  arrange(station_id_2) %>% 
  print(n = Inf)

# so looking at these is appears we maybe have slightly tighter residuals at the trend stations but that would require some more specific distributional tests. However the main takeaway is that while the sample size at a point is likely impacting that se.fit value it is not the only driving factor as there are more se.fit values than there are unique sample sizes. 

```

